# JobRonin â€” Jobs Pipeline

This service turns raw job posts from multiple sources into **canonical, query-ready data** and provides a thin API/worker surface the rest of JobRonin can use for matching.

## Scope in the broader project

- **Owned here**
  - SQL pipeline: **Bronze â†’ Silver â†’ Gold** (normalize, dedupe, field-level enrichment).
  - Matching storage: `Agent`, `SearchSession`, `MatchResult` (results cached per session).
  - Minimal API (health now; matching endpoints later).
  - Nightly orchestration (local and GitHub Actions).

- **Not owned here**
  - Scrapers (JobSpy, StepStone, â€¦) â€” separate repos push into Bronze tables.
  - Contact enrichment + Browser-Use automations â€” sibling worker/service.
  - Front-ends (Lovable web app, Chrome extension) â€” consume this repoâ€™s API.

## ğŸ“š Documentation

**Business (high level)**
- ğŸ§­ One-pager: [docs/business/one-pager.md](docs/business/one-pager.md)
- ğŸ“‹ Business requirements: [docs/business/requirements.md](docs/business/requirements.md)

**Engineering (diagrams)**
- ğŸ§± System architecture: [docs/engineering/system-architecture.md](docs/engineering/system-architecture.md)
- ğŸŒ™ Nightly ETL sequence: [docs/engineering/nightly-etl-sequence.md](docs/engineering/nightly-etl-sequence.md)
- ğŸ¤– Agent search & enrichment sequence: [docs/engineering/agent-search-sequence.md](docs/engineering/agent-search-sequence.md)
- ğŸ—ºï¸ Conceptual ERD: [docs/engineering/conceptual-erd.md](docs/engineering/conceptual-erd.md)

## Repository layout

```text
.
â”œâ”€â”€ api/                      # Thin FastAPI app (health now; search endpoints later)
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ worker/                   # Background worker stub (LLM verify, contacts, Browser-Use later)
â”‚   â””â”€â”€ runner.py
â”œâ”€â”€ orchestration/            # Local runner for SQL transforms
â”‚   â””â”€â”€ run_nightly.py
â”œâ”€â”€ transforms/
â”‚   â””â”€â”€ sql/                  # SQL-first pipeline (executed in lexical order)
â”‚       â”œâ”€â”€ 00_extensions.sql
â”‚       â”œâ”€â”€ 01_silver_jobspy.sql
â”‚       â”œâ”€â”€ 02_silver_stepstone.sql
â”‚       â”œâ”€â”€ 03_unified_stage.sql
â”‚       â”œâ”€â”€ 10_gold_company.sql
â”‚       â”œâ”€â”€ 11_gold_job_post.sql
â”‚       â”œâ”€â”€ 12_upsert_companies.sql
â”‚       â”œâ”€â”€ 13_upsert_jobs_deterministic.sql
â”‚       â”œâ”€â”€ 14_upsert_jobs_fuzzy.sql
â”‚       â”œâ”€â”€ 20_enrich_apply_url.sql
â”‚       â”œâ”€â”€ 21_enrich_salary.sql
â”‚       â”œâ”€â”€ 22_enrich_description.sql
â”‚       â”œâ”€â”€ 23_enrich_emails.sql
â”‚       â””â”€â”€ 40_matching.sql
â”œâ”€â”€ infra/                    # Placeholder for IaC/deploy
â”œâ”€â”€ scripts/                  # Helper scripts (optional)
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ nightly.yml       # Nightly SQL transforms on main
â”œâ”€â”€ .env                      # Local config (gitignored)
â”œâ”€â”€ .env.sample               # Template for .env
â”œâ”€â”€ requirements.txt          # Minimal runtime deps
â”œâ”€â”€ Makefile                  # install, api, worker, run-sql, nightly
â””â”€â”€ docs/                     # Business + engineering docs

```

## Environment & config

Create `.env` from the sample:

DATABASE_URL=postgres://USER:PASS@HOST:5432/DBNAME
APP_PORT=8000

- `DATABASE_URL` is required for DB ops (`make run-sql`, API health, orchestration).
- In CI/GitHub Actions, set `DATABASE_URL` as a **repository secret**.

## Getting started (local)

cp .env.sample .env
pip install -r requirements.txt
make run-sql
make api
# optional
make worker

## Nightly pipeline (CI on main)

The workflow at .github/workflows/nightly.yml runs on **main** at 0 20 * * * (20:00 UTC). To enable:

1. GitHub â†’ Settings â†’ Secrets and variables â†’ Actions â†’ New repository secret
   - Name: DATABASE_URL
   - Value: your production Postgres URL
2. Ensure SQL files are correctly ordered (lexical order = run order).
3. You can manually trigger via Actions â†’ nightly â†’ Run workflow.

## How it fits together

- Scrapers write Bronze raw tables.
- Silver views normalize per source; Gold tables dedupe into canonical Company/JobPost.
- Enrichment fills missing fields per-field (no regress); Features precompute search signals.
- Matching writes session results so UIs can page/click without recompute.
- Decision-makers & contacts happen in a sibling worker/service; API can read those canonical people tables.

See docs/engineering/ for diagrams.

## Troubleshooting

- Mermaid diagrams not rendering on GitHub: each block must start with ```mermaid and end with ```. Keep labels simple.
- make run-sql says â€œDATABASE_URL not setâ€: ensure .env exists; or export to shell: export $(cat .env | xargs)
- DB connect errors: verify network/allowlist/SSL (try ?sslmode=require).
- Action fails on psql: confirm DATABASE_URL secret exists on the repo and branch main.

## Next steps

- Fill Silver views for JobSpy & StepStone with the unified column set.
- Implement Gold DDL for company, company_alias, job_post, job_source_link.
- Add deterministic + blocked fuzzy upserts, then field-level enrichment SQL.
- Create matching tables and match_fn(session_id) (Filter + Rank).
- Expose /v1/search and /v1/search/{session_id}/results in api/.
- Stand up the separate decision-maker worker for contact fetch & caching.

Default branch: main
git branch -M main
git push -u origin main
